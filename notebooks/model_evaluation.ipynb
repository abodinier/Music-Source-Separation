{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kaituoxu.conv_tasnet import ConvTasNet\n",
    "from asteroid.data import MUSDB18Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"musdb_data\")\n",
    "\n",
    "TEST_SONG = DATA_DIR/\"test/Al James - Schoolboy Facination.stem.mp4\"\n",
    "\n",
    "TRAINING_DIR = Path('weights/training_20220308-170315')\n",
    "cfg_path = TRAINING_DIR/\"cfg.yaml\"\n",
    "history_path = TRAINING_DIR/\"history.csv\"\n",
    "best_model_path = TRAINING_DIR/\"model.pth\"\n",
    "\n",
    "try:\n",
    "    last_model_path = sorted(list(TRAINING_DIR.glob(\"model_epoch*\")), key=lambda x: int(\"\".join(re.findall(r\"\\d\", str(x)))))[-1]\n",
    "except:\n",
    "    last_model_path = None\n",
    "\n",
    "with open(str(cfg_path), 'r') as file:\n",
    "    CFG = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "assert cfg_path.exists() and history_path.exists() and best_model_path.exists() and cfg_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in CFG.items():\n",
    "    print(f\">>> {key.upper()} -> {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(history_path)\n",
    "epochs = df.index.values\n",
    "train_loss = df.train_loss\n",
    "val_loss = df.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(epochs, train_loss, label='train loss')\n",
    "plt.plot(epochs, val_loss, label='val loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations :\n",
    "- The model does not learn ! Instability ?\n",
    "  - Solutions ?:\n",
    "    - Reduce learning rate\n",
    "    - Increase batch size\n",
    "    - Store the learning rate at each epoch\n",
    "    - Store other metrics\n",
    "    - Store gradients norms\n",
    "\n",
    "<br/>\n",
    "\n",
    "- Maybe use smaller network ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = CFG[\"targets\"]\n",
    "SAMPLE_RATE = CFG[\"sample_rate\"]\n",
    "\n",
    "LR = CFG[\"learning_rate\"]\n",
    "N_EPOCHS = CFG[\"n_epochs\"]\n",
    "\n",
    "TRAIN_BATCH_SIZE = CFG[\"train_batch_size\"]\n",
    "TEST_BATCH_SIZE = CFG[\"test_batch_size\"]\n",
    "\n",
    "N_SRC = len(TARGETS)\n",
    "X = CFG[\"X\"]\n",
    "R = CFG[\"R\"]\n",
    "B = CFG[\"B\"]\n",
    "H = CFG[\"H\"]\n",
    "Sc = CFG[\"Sc\"]\n",
    "P = CFG[\"P\"]\n",
    "L = CFG[\"L\"]\n",
    "N = CFG[\"N\"]\n",
    "STRIDE = CFG[\"stride\"]\n",
    "CLIP = CFG[\"gradient_clipping\"]\n",
    "\n",
    "model = ConvTasNet(\n",
    "    C=N_SRC,\n",
    "    X=X,\n",
    "    R=R,\n",
    "    B=B,\n",
    "    H=H,\n",
    "    P=P,\n",
    "    L=L,\n",
    "    N=N,\n",
    "    mask_nonlinear=\"softmax\"\n",
    ")\n",
    "model.load_state_dict(torch.load(best_model_path)[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Separation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound, sr = librosa.load(TEST_SONG.__str__(), sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = torch.tensor(sound[:10 * SAMPLE_RATE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(sound.view(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(TARGETS):\n",
    "    wavfile.write(f\"./{name}.wav\", SAMPLE_RATE, pred[i].detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ee98f8cc5c61c7bb85862890f9fa26c929bedb663baf44f10e1854389fd85ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
